
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>cluster_slug: Bayesian Inference of Star Cluster Properties &#8212; slug 2.0 documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '2.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="sfr_slug: Bayesian Inference of Star Formation Rates" href="sfr_slug.html" />
    <link rel="prev" title="bayesphot: Bayesian Inference for Stochastic Stellar Populations" href="bayesphot.html" />
   
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9">

  </head>
  <body>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="cluster-slug-bayesian-inference-of-star-cluster-properties">
<span id="sec-cluster-slug"></span><h1>cluster_slug: Bayesian Inference of Star Cluster Properties<a class="headerlink" href="#cluster-slug-bayesian-inference-of-star-cluster-properties" title="Permalink to this headline">¶</a></h1>
<p>The slugpy.cluster_slug module computes posterior probabilities for the mass, age, and extinction of star clusters from a set of input photometry.  It is implemented as a wrapper around <a class="reference internal" href="bayesphot.html#sec-bayesphot"><span class="std std-ref">bayesphot: Bayesian Inference for Stochastic Stellar Populations</span></a>, so for details on how the calculation is performed see the bayesphot documentation.</p>
<div class="section" id="getting-the-default-library">
<h2>Getting the Default Library<a class="headerlink" href="#getting-the-default-library" title="Permalink to this headline">¶</a></h2>
<p>The cluster_slug module requires a pre-computed library of slug simulations to use as a “training set” for its calculations. Due to its size, the default library <em>is not</em> included in the slug git repository. Instead, it is provided for download from the <a class="reference external" href="http://www.slugsps.com/data">SLUG data products website</a>. Download the two files <code class="docutils literal"><span class="pre">clusterslug_mw_cluster_phot.fits</span></code> and <code class="docutils literal"><span class="pre">clusterslug_mw_cluster_prop.fits</span></code> and save them in the <code class="docutils literal"><span class="pre">cluster_slug</span></code> directory of the main respository. If you do not do so, and do not provide your own library when you attempt to use cluster_slug, you will be prompted to download the default library.</p>
</div>
<div class="section" id="basic-usage">
<h2>Basic Usage<a class="headerlink" href="#basic-usage" title="Permalink to this headline">¶</a></h2>
<p>For an example of how to use cluster_slug, see the file <code class="docutils literal"><span class="pre">cluster_slug/cluster_slug_example.py</span></code> in the repository. All funtionality is provided through the cluster_slug class. The basic steps are as follows:</p>
<ol class="arabic">
<li><p class="first">Import the library and instantiate an <code class="docutils literal"><span class="pre">sfr_slug</span></code> object (see <a class="reference internal" href="#ssec-cluster-slug-full"><span class="std std-ref">Full Documentation of slugpy.cluster_slug</span></a> for full details):</p>
<div class="highlight-rest"><div class="highlight"><pre><span></span>from slugpy.cluster_slug import cluster_slug
cs = cluster_slug(photsystem=photsystem)
</pre></div>
</div>
</li>
</ol>
<p>This creates a cluster_slug object, using the default simulation library. If you have another library of simulations you’d rather use, you can use the <code class="docutils literal"><span class="pre">libname</span></code> keyword to the <code class="docutils literal"><span class="pre">cluster_slug</span></code> constructor to select it. The optional argument <code class="docutils literal"><span class="pre">photsystem</span></code> specifies the photometric system you will be using for your data. Possible values are <code class="docutils literal"><span class="pre">L_nu</span></code> (flux per unit frequency, in erg/s/Hz), <code class="docutils literal"><span class="pre">L_lambda</span></code> (flux per unit wavelength, in erg/s/Angstrom), <code class="docutils literal"><span class="pre">AB</span></code> (AB magnitudes), <code class="docutils literal"><span class="pre">STMAG</span></code> (ST magnitudes), and <code class="docutils literal"><span class="pre">Vega</span></code> (Vega magnitudes). If left unspecified, the photometric system will be whatever the library was written in; the default library is in the <code class="docutils literal"><span class="pre">L_nu</span></code> system. Finally, if you have already read a library into memory using <code class="docutils literal"><span class="pre">read_cluster</span></code>, you can set the keyword <code class="docutils literal"><span class="pre">lib</span></code> in the <code class="docutils literal"><span class="pre">cluster_slug</span></code> constructor to specify that library should be used.</p>
<ol class="arabic" start="2">
<li><p class="first">Specify your filter(s), for example:</p>
<div class="highlight-rest"><div class="highlight"><pre><span></span>cs.add_filters([&#39;WFC3_UVIS_F336W&#39;, &#39;WFC3_UVIS_F438W&#39;, &#39;WFC3_UVIS_F555W&#39;,
                &#39;WFC3_UVIS_F814W&#39;, &#39;WFC3_UVIS_F657N&#39;])
</pre></div>
</div>
</li>
</ol>
<p>The <code class="docutils literal"><span class="pre">add_filter</span></code> method takes as an argument a string or list of strings specifying which filters were used for the observations you’re going to analyze. You can have more than one set of filters active at a time (just by calling <code class="docutils literal"><span class="pre">add_filters</span></code> more than once), and then specify which set of filters you’re using for any given calculation.</p>
<ol class="arabic" start="3">
<li><p class="first">Specify your priors, for example:</p>
<div class="highlight-rest"><div class="highlight"><pre><span></span># Set priors to be flat in log T and A_V, but vary with log M as
# p(log M) ~ 1/M
def priorfunc(physprop):
   # Note: physprop is an array of shape (N, 3) where physprop[:,0] =
   # log M, physprop[:,1] = log T, physprop[:,2] = A_V
   return 1.0/exp(physprop[:,0])
cs.priors = prorfunc
</pre></div>
</div>
</li>
</ol>
<p>The <code class="docutils literal"><span class="pre">priors</span></code> property specifies the assumed prior probability distribution on the physical properties of star clusters. It can be either <code class="docutils literal"><span class="pre">None</span></code> (in which case all simulations in the library are given equal prior probability), an array with as many elements as there are simulations in the library giving the prior for each one, or a callable that takes a vector of physical properties as input and returns the prior for it.</p>
<ol class="arabic" start="4">
<li><p class="first">Generate a marginal posterior probability distribuiton via:</p>
<div class="highlight-rest"><div class="highlight"><pre><span></span>logm, pdf = cs.mpdf(idx, phot, photerr = photerr)
</pre></div>
</div>
</li>
</ol>
<p>The first argument <code class="docutils literal"><span class="pre">idx</span></code> is an index for which posterior distribution should be computed – a value of 0 generates the posterior in log mass, a value of 1 generates the posterion on log age, and a value of generates the posterior in A_V. The second argument <code class="docutils literal"><span class="pre">phot</span></code> is an array giving the photometric values in the filters specified in step 2; make sure you’re using the same photometric system you used in step 1. For the array <code class="docutils literal"><span class="pre">phot</span></code>, the trailing dimension must match the number of filters, and the marginal posterior-finding exercise is repeated over every value in the leading dimensions. If you have added two or more filter sets, you need to specify which one you want to use via the <code class="docutils literal"><span class="pre">filters</span></code> keyword. The optional argument <code class="docutils literal"><span class="pre">photerr</span></code> can be used to provide errors on the photometric values. The shape rules on it are the same as on <code class="docutils literal"><span class="pre">phot</span></code>, and the two leading dimensions of the two arrays will be broadcast together using normal broadcasting rules.</p>
<p>The <code class="docutils literal"><span class="pre">cluster_slug.mpdf</span></code> method returns a tuple of two quantities. The first is a grid of values for log M, log T, or A_V, depending on the value of <code class="docutils literal"><span class="pre">idx</span></code>. The second is the posterior probability distribution at each value of of the grid. Posteriors are normalized to have unit integral. If the input consisted of multiple sets of photometric values, the output will contains marginal posterior probabilities for each input. The output grid will be created automatically be default, but all aspects of it (shape, size, placement of grid points) can be controlled by keywords – see <a class="reference internal" href="#ssec-cluster-slug-full"><span class="std std-ref">Full Documentation of slugpy.cluster_slug</span></a>.</p>
</div>
<div class="section" id="using-cluster-slug-in-parallel">
<h2>Using cluster_slug in Parallel<a class="headerlink" href="#using-cluster-slug-in-parallel" title="Permalink to this headline">¶</a></h2>
<p>The <code class="docutils literal"><span class="pre">cluster_slug</span></code> module has full support for threaded computation using the python <a class="reference external" href="https://docs.python.org/2.7/library/multiprocessing.html">multiprocessing module</a>. This allows efficient use of multiple cores on a shared memory machine, without the need for every project to read a large simulation library or store it in memory. See <a class="reference internal" href="bayesphot.html#ssec-bayesphot-threading"><span class="std std-ref">Parallelism in bayesphot</span></a> for full details on the recommended paradigm for parallel computing. The full list of thread-safe <code class="docutils literal"><span class="pre">cluster_slug</span></code> methods is:</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">cluster_slug.logL</span></code></li>
<li><code class="docutils literal"><span class="pre">cluster_slug.mpdf</span></code></li>
<li><code class="docutils literal"><span class="pre">cluster_slug.mcmc</span></code></li>
<li><code class="docutils literal"><span class="pre">cluster_slug.bestmatch</span></code></li>
<li><code class="docutils literal"><span class="pre">cluster_slug.make_approx_phot</span></code></li>
<li><code class="docutils literal"><span class="pre">cluster_slug.make_approx_phys</span></code></li>
<li><code class="docutils literal"><span class="pre">cluster_slug.squeeze_rep</span></code></li>
<li><code class="docutils literal"><span class="pre">cluster_slug.mpdf_approx</span></code></li>
</ul>
</div>
<div class="section" id="making-your-own-library">
<h2>Making Your Own Library<a class="headerlink" href="#making-your-own-library" title="Permalink to this headline">¶</a></h2>
<p>You can generate your own library by running slug; you might want to do this, for example, to have a library that works at different metallicity or for a different set of stellar tracks. An example parameter file (the one that was used to generate the default clusterslug_mw library) is included in the <code class="docutils literal"><span class="pre">cluster_slug</span></code> directory. This file uses slug’s capability to pick the output time and the cluster mass from specified PDFs.</p>
<p>One subtle post-processing step you should take once you’ve generated your library is to read it in using <a class="reference internal" href="slugpy.html#sec-slugpy"><span class="std std-ref">slugpy – The Python Helper Library</span></a> and then write the photometry back out using the <code class="docutils literal"><span class="pre">slugpy.write_cluster_phot</span></code> routine with the format set to <code class="docutils literal"><span class="pre">fits2</span></code>. This uses an alternative FITS format that is faster to search when you want to load only a few filters out of a large library. For large data sets, this can reduce cluster_slug load times by an order of magnitude. (To be precise: the default format for FITS outputs to put all filters into a single binary table HDU, while the <code class="docutils literal"><span class="pre">fits2</span></code> format puts each filter in its own HDU. This puts all data for a single filter into a contiguous block, rather than all the data for a single cluster into a contiguous block, and is therefore faster to load when one wants to load the data filter by filter.)</p>
</div>
<div class="section" id="variable-mode-imf">
<h2>Variable Mode IMF<a class="headerlink" href="#variable-mode-imf" title="Permalink to this headline">¶</a></h2>
<p>If your library was run with variable IMF parameters, these can also be used in <code class="docutils literal"><span class="pre">cluster_slug</span></code>. When creating a <code class="docutils literal"><span class="pre">cluster_slug</span></code> object, you can pass the array <code class="docutils literal"><span class="pre">vp_list</span></code> as an argument. This list should have an element for each variable parameter in your library. Each element should then be either <code class="docutils literal"><span class="pre">True</span></code> or <code class="docutils literal"><span class="pre">False</span></code> depending on whether you wish to include this parameter in the analysis.
For example, for a library with four variable parameters you could have:</p>
<div class="highlight-rest"><div class="highlight"><pre><span></span>vp_list=[True,False,True,True]
</pre></div>
</div>
</div>
<div class="section" id="full-documentation-of-slugpy-cluster-slug">
<span id="ssec-cluster-slug-full"></span><h2>Full Documentation of slugpy.cluster_slug<a class="headerlink" href="#full-documentation-of-slugpy-cluster-slug" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="slugpy.cluster_slug.cluster_slug">
<em class="property">class </em><code class="descclassname">slugpy.cluster_slug.</code><code class="descname">cluster_slug</code><span class="sig-paren">(</span><em>libname=None</em>, <em>filters=None</em>, <em>photsystem=None</em>, <em>lib=None</em>, <em>bw_phys=0.1</em>, <em>bw_phot=None</em>, <em>ktype='gaussian'</em>, <em>priors=None</em>, <em>sample_density=None</em>, <em>pobs=None</em>, <em>reltol=0.01</em>, <em>abstol=1e-08</em>, <em>leafsize=16</em>, <em>use_nebular=True</em>, <em>use_extinction=True</em>, <em>thread_safe=True</em>, <em>pruning=False</em>, <em>caching='none'</em>, <em>vp_list=[]</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/slugpy/cluster_slug/cluster_slug.html#cluster_slug"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#slugpy.cluster_slug.cluster_slug" title="Permalink to this definition">¶</a></dt>
<dd><p>A class that can be used to estimate the PDF of star cluster
properties (mass, age, extinction) from a set of input photometry
in various bands.</p>
<dl class="docutils">
<dt>Properties</dt>
<dd><dl class="first last docutils">
<dt>priors <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (N) | callable | None</span></dt>
<dd>prior probability on each data point; interpretation
depends on the type passed; array, shape (N): values are
interpreted as the prior probability of each data point;
callable: the callable must take as an argument an array
of shape (N, nphys), and return an array of shape (N)
giving the prior probability at each data point; None:
all data points have equal prior probability</dd>
<dt>abstol <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>absolute error tolerance for kernel density estimation</dd>
<dt>reltol <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>relative error tolerance for kernel density estimation</dd>
<dt>thread_safe <span class="classifier-delimiter">:</span> <span class="classifier">bool</span></dt>
<dd>if True, the computation routines will run in thread-safe
mode, allowing use with multiprocessing; this incurs a small
performance penalty</dd>
</dl>
</dd>
<dt>Methods</dt>
<dd><dl class="first last docutils">
<dt>filters() <span class="classifier-delimiter">:</span> <span class="classifier"></span></dt>
<dd>returns list of filters available in the library</dd>
<dt>filtersets() :</dt>
<dd>return a list of the currently-loaded filter sets</dd>
<dt>filter_units() :</dt>
<dd>returns units for available filters</dd>
<dt>add_filters() <span class="classifier-delimiter">:</span> <span class="classifier"></span></dt>
<dd>adds a set of filters for use in parameter estimation</dd>
<dt>logL() <span class="classifier-delimiter">:</span> <span class="classifier"></span></dt>
<dd>compute log likelihood at a particular set of physical and
photometric parameters</dd>
<dt>mpdf() <span class="classifier-delimiter">:</span> <span class="classifier"></span></dt>
<dd>computer marginal posterior probability distribution for a
set of photometric measurements</dd>
<dt>mcmc() :</dt>
<dd>due MCMC estimation of the posterior PDF on a set of
photometric measurments</dd>
<dt>bestmatch() <span class="classifier-delimiter">:</span> <span class="classifier"></span></dt>
<dd>find the simulations in the library that are the closest
matches to the input photometry</dd>
<dt>make_approx_phot() :</dt>
<dd>given a set of physical properties, return a set of points
that can be used for fast approximation of the corresponding
photometric properties</dd>
<dt>make_approx_phys() :</dt>
<dd>given a set of photometric properties, return a set of points
that can be used for fast approximation of the corresponding
physical properties</dd>
<dt>draw_sample():</dt>
<dd>draw a random sample of cluster physical and photometric
properties</dd>
<dt>draw_phot():</dt>
<dd>given a set of physical properties, return a
randomly-selected set of photometric properties</dd>
</dl>
</dd>
</dl>
<dl class="method">
<dt id="slugpy.cluster_slug.cluster_slug.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>libname=None</em>, <em>filters=None</em>, <em>photsystem=None</em>, <em>lib=None</em>, <em>bw_phys=0.1</em>, <em>bw_phot=None</em>, <em>ktype='gaussian'</em>, <em>priors=None</em>, <em>sample_density=None</em>, <em>pobs=None</em>, <em>reltol=0.01</em>, <em>abstol=1e-08</em>, <em>leafsize=16</em>, <em>use_nebular=True</em>, <em>use_extinction=True</em>, <em>thread_safe=True</em>, <em>pruning=False</em>, <em>caching='none'</em>, <em>vp_list=[]</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/slugpy/cluster_slug/cluster_slug.html#cluster_slug.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#slugpy.cluster_slug.cluster_slug.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize a cluster_slug object.</p>
<dl class="docutils">
<dt>Parameters</dt>
<dd><dl class="first last docutils">
<dt>libname <span class="classifier-delimiter">:</span> <span class="classifier">string</span></dt>
<dd>name of the SLUG model to load; if left as None, the default
is $SLUG_DIR/cluster_slug/modp020_chabrier_MW</dd>
<dt>lib <span class="classifier-delimiter">:</span> <span class="classifier">object</span></dt>
<dd>a library read by the read_cluster function; if specified
this overrides the libname option; the library must
contain both physical properties and photometry, and
must include filter data; if this is not None, then the 
photsystem keyword is ignored</dd>
<dt>filters <span class="classifier-delimiter">:</span> <span class="classifier">iterable of stringlike</span></dt>
<dd>list of filter names to be used for inferenence</dd>
<dt>photsystem <span class="classifier-delimiter">:</span> <span class="classifier">None or string</span></dt>
<dd>If photsystem is None, the library will be left in
whatever photometric system was used to write
it. Alternately, if it is a string, the data will be
converted to the specified photometric system. Allowable
values are ‘L_nu’, ‘L_lambda’, ‘AB’, ‘STMAG’, and
‘Vega’, corresponding to the options defined in the SLUG
code. Once this is set, any subsequent photometric data
input are assumed to be in the same photometric system.</dd>
<dt>bw_phys <span class="classifier-delimiter">:</span> <span class="classifier">‘auto’ | float | array, shape (2) | array, shape (3)</span></dt>
<dd>bandwidth for the physical quantities in the kernel
density estimation; if set to ‘auto’, the bandwidth will
be estimated automatically; if set to a scalar quantity,
this will be used for all physical quantities; if set to
an array, the array must have 2 elements if
use_extinction is False, or 3 if it is True</dd>
<dt>bw_phot <span class="classifier-delimiter">:</span> <span class="classifier">None | ‘auto’ | float | array</span></dt>
<dd>bandwidth for the photometric quantities; if set to
None, defaults to 0.25 mag / 0.1 dex; if set to ‘auto’,
bandwidth is estimated automatically; if set to a float,
this bandwidth is used for all photometric dimensions;
if set to an array, the array must have the same number
of dimensions as len(filters)</dd>
<dt>ktype <span class="classifier-delimiter">:</span> <span class="classifier">string</span></dt>
<dd>type of kernel to be used in densty estimation; allowed
values are ‘gaussian’ (default), ‘epanechnikov’, and
‘tophat’; only Gaussian can be used with error bars</dd>
<dt>priors <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (N) | callable | None</span></dt>
<dd>prior probability on each data point; interpretation
depends on the type passed; array, shape (N): values are
interpreted as the prior probability of each data point;
callable: the callable must take as an argument an array
of shape (N, nphys), and return an array of shape (N)
giving the prior probability at each data point; None:
all data points have equal prior probability</dd>
<dt>pobs <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (N) | callable | None</span></dt>
<dd>probability of being observed on each data point; interpretation
depends on the type passed; array, shape (N): values are
interpreted as the prior probability of each data point;
callable: the callable must take as an argument an array
of shape (N, nphys), and return an array of shape (N)
giving the prior probability at each data point; None:
all data points have equal prior probability</dd>
<dt>sample_density <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (N) | callable | ‘auto’ | None</span></dt>
<dd>the density of the data samples at each data point; this
need not match the prior density; interpretation depends
on the type passed; array, shape (N): values are
interpreted as the density of data sampling at each
sample point; callable: the callable must take as an
argument an array of shape (N, nphys), and return an
array of shape (N) giving the sampling density at each
point; ‘auto’: the sample density will be computed
directly from the data set; note that this can be quite
slow for large data sets, so it is preferable to specify
this analytically if it is known; None: data are assumed
to be uniformly sampled, or to be sampled as the default
library is if libname is also None</dd>
<dt>reltol <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>relative error tolerance; errors on all returned
probabilities p will satisfy either
abs(p_est - p_true) &lt;= reltol * p_est   OR
abs(p_est - p_true) &lt;= abstol,
where p_est is the returned estimate and p_true is the
true value</dd>
<dt>abstol <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>absolute error tolerance; see above</dd>
<dt>leafsize <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>number of data points in each leaf of the KD tree</dd>
<dt>use_nebular <span class="classifier-delimiter">:</span> <span class="classifier">bool</span></dt>
<dd>if True, photometry including nebular emission will be
used if available; if not, nebular emission will be
omitted</dd>
<dt>use_extinction <span class="classifier-delimiter">:</span> <span class="classifier">bool</span></dt>
<dd>if True, photometry including extinction will be used;
if not, it will be omitted, and in this case no results
making use of the A_V dimension will be available</dd>
<dt>thread_safe <span class="classifier-delimiter">:</span> <span class="classifier">bool</span></dt>
<dd>if True, cluster_slug will make extra copies of internals
as needed to ensure thread safety when the computation
routines (logL, mpdf, mcmc, bestmatch, make_approx_phot,
make_approx_phys, mpdf_approx) are used with
multiprocessing; this incurs a minor performance
penalty, and can be disabled by setting to False if the
code will not be run with the multiprocessing module</dd>
<dt>pruning <span class="classifier-delimiter">:</span> <span class="classifier">bool</span></dt>
<dd>if True, the underlying bayesphot objects will be pruned
of clusters for which pobs or priors are zero, speeding
up evaluations; the current implementation is limited in
that pruning for priors is only done when the
cluster_slug object is instantiated, and pruning for
pobs is only done when each filter set is added, so the
list of pruned clusters cannot be modified later</dd>
<dt>caching <span class="classifier-delimiter">:</span> <span class="classifier">‘aggressive’ | ‘lazy’ | ‘none’</span></dt>
<dd><p class="first">strategy for caching subsets of the data with some
dimensions marginalised out; behavior is as follows:</p>
<blockquote class="last">
<div><dl class="docutils">
<dt>‘agressive’</dt>
<dd>on construction, store sorted data for fast
calculation of 1D PDFs of variables by themselves,
and 1D PDFs of all physical variables marginalised
over all other physical variables; this
significantly increases the memory footprint and
construction time, but greatly speeds up
subsequent evaluation of any of these quantities,
and is generally the best choice for prudction
work in parallel</dd>
<dt>‘lazy’</dt>
<dd>sorted data sets for fast computation are created
and cached as needed; this will make the first
computation of any marginal PDF slower, but speed
up all subsequent ones, without imposing any
extra time at initial construction; this mode is
generally best for interactive work, but is not
thread_safe = True; memory cost depends on how
many different marginal PDF combinations are
calculated, but is always less than aggressive</dd>
<dt>‘none’</dt>
<dd>no caching is performed automatically; the user
may still manually cache data by calling
the make_cache method</dd>
</dl>
</div></blockquote>
</dd>
<dt>vp_list <span class="classifier-delimiter">:</span> <span class="classifier">list</span></dt>
<dd>A list with an element for each of the variable parameters
in the data. An element is set to True if we wish to use
that parameter here, or False if we do not.</dd>
</dl>
</dd>
<dt>Returns</dt>
<dd>Nothing</dd>
<dt>Raises</dt>
<dd>IOError, if the library cannot be found</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="slugpy.cluster_slug.cluster_slug.__weakref__">
<code class="descname">__weakref__</code><a class="headerlink" href="#slugpy.cluster_slug.cluster_slug.__weakref__" title="Permalink to this definition">¶</a></dt>
<dd><p>list of weak references to the object (if defined)</p>
</dd></dl>

<dl class="method">
<dt id="slugpy.cluster_slug.cluster_slug.add_filters">
<code class="descname">add_filters</code><span class="sig-paren">(</span><em>filters</em>, <em>bandwidth=None</em>, <em>pobs=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/slugpy/cluster_slug/cluster_slug.html#cluster_slug.add_filters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#slugpy.cluster_slug.cluster_slug.add_filters" title="Permalink to this definition">¶</a></dt>
<dd><p>Add a set of filters to use for cluster property estimation</p>
<dl class="docutils">
<dt>Parameters</dt>
<dd><dl class="first last docutils">
<dt>filters <span class="classifier-delimiter">:</span> <span class="classifier">iterable of stringlike</span></dt>
<dd>list of filter names to be used for inferenence</dd>
<dt>bandwidth <span class="classifier-delimiter">:</span> <span class="classifier">None | ‘auto’ | float | array</span></dt>
<dd>bandwidth for the photometric quantities; if set to
None, the bandwidth is unchanged for an existing filter
set, and for a newly-created one the default physical
and photometric bandwidths are used; if set to ‘auto’,
bandwidth is estimated automatically; if set to a float,
this bandwidth is used for all physical and photometric
dimensions; if set to an array, the array must have the
same number of entries as nphys+len(filters)</dd>
<dt>pobs <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (N) | callable | ‘equal’ | None</span></dt>
<dd>the probability that a particular object would be observed,
which is used, like prior, to weight the library;
interpretation depends on type. ‘equal’ means all objects are
equally likely to be observed, array is an array giving the
observation probability of each object in the library, and
callable means must be a function that takes an array
containing the photometry, of shape (N, nhpot), as an
argument, and returns an array of shape (N) giving the
probability of observation for that object. Finally,
None leaves the observational probability unchanged</dd>
</dl>
</dd>
<dt>Returns</dt>
<dd>nothing</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="slugpy.cluster_slug.cluster_slug.bestmatch">
<code class="descname">bestmatch</code><span class="sig-paren">(</span><em>phot</em>, <em>photerr=None</em>, <em>nmatch=1</em>, <em>bandwidth_units=False</em>, <em>filters=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/slugpy/cluster_slug/cluster_slug.html#cluster_slug.bestmatch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#slugpy.cluster_slug.cluster_slug.bestmatch" title="Permalink to this definition">¶</a></dt>
<dd><p>Searches through the simulation library and returns the closest
matches to an input set of photometry.</p>
<dl class="docutils">
<dt>Parameters:</dt>
<dd><dl class="first last docutils">
<dt>phot <span class="classifier-delimiter">:</span> <span class="classifier">arraylike, shape (nfilter) or (…, nfilter)</span></dt>
<dd>array giving the photometric values; for a
multidimensional array, the operation is vectorized over
the leading dimensions</dd>
<dt>photerr <span class="classifier-delimiter">:</span> <span class="classifier">arraylike, shape (nfilter) or (…, nfilter)</span></dt>
<dd>array giving photometric errors, which must have the
same shape as phot; if this is not None,
then distances will be measured in units of the
photometric error if bandwidth_units is False, or in
units of the bandwidth added in quadrature with the
errors if it is True</dd>
<dt>nmatch <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>number of matches to return; returned matches will be
ordered by distance from the input</dd>
<dt>bandwidth_units <span class="classifier-delimiter">:</span> <span class="classifier">bool</span></dt>
<dd>if False, distances are computed based on the
logarithmic difference in luminosity; if True, they are
measured in units of the bandwidth</dd>
<dt>filters <span class="classifier-delimiter">:</span> <span class="classifier">listlike of strings</span></dt>
<dd>list of photometric filters to use; if left as None, and
only 1 set of photometric filters has been defined for
the cluster_slug object, that set will be used by
default</dd>
</dl>
</dd>
<dt>Returns:</dt>
<dd><dl class="first last docutils">
<dt>matches <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (…, nmatch, nphys + nfilter)</span></dt>
<dd>best matches to the input photometry; shape in the
leading dimensions will be the same as for phot, and if
nmatch == 1 then that dimension will be omitted; in the
final dimension, the first 3 elements give log M, log T,
and A_V, while the last nfilter give the photometric
values; if created with use_extinct = False, the A_V
dimension is omitted</dd>
<dt>dist <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (…, nmatch)</span></dt>
<dd>distances between the matches and the input photometry</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="slugpy.cluster_slug.cluster_slug.bestmatch_phys">
<code class="descname">bestmatch_phys</code><span class="sig-paren">(</span><em>phys</em>, <em>nmatch=1</em>, <em>bandwidth_units=False</em>, <em>filters=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/slugpy/cluster_slug/cluster_slug.html#cluster_slug.bestmatch_phys"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#slugpy.cluster_slug.cluster_slug.bestmatch_phys" title="Permalink to this definition">¶</a></dt>
<dd><p>Searches through the simulation library and returns the closest
matches to an input set of photometry.</p>
<dl class="docutils">
<dt>Parameters:</dt>
<dd><dl class="first last docutils">
<dt>phys <span class="classifier-delimiter">:</span> <span class="classifier">arraylike, shape (nphys) or (…, nphys)</span></dt>
<dd>array giving the physical values; for a
multidimensional array, the operation is vectorized over
the leading dimensions</dd>
<dt>nmatch <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>number of matches to return; returned matches will be
ordered by distance from the input</dd>
<dt>bandwidth_units <span class="classifier-delimiter">:</span> <span class="classifier">bool</span></dt>
<dd>if False, distances are computed based on the
logarithmic difference in physical properties; if True,
they are measured in units of the bandwidth</dd>
<dt>filters <span class="classifier-delimiter">:</span> <span class="classifier">listlike of strings</span></dt>
<dd>list of photometric filters to use; if left as None, and
only 1 set of photometric filters has been defined for
the cluster_slug object, that set will be used by
default</dd>
</dl>
</dd>
<dt>Returns:</dt>
<dd><dl class="first last docutils">
<dt>matches <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (…, nmatch, nphys + nfilter)</span></dt>
<dd>best matches to the input properties; shape in the
leading dimensions will be the same as for phot, and if
nmatch == 1 then that dimension will be omitted</dd>
<dt>dist <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (…, nmatch)</span></dt>
<dd>distances between the matches and the input physical
properties</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="slugpy.cluster_slug.cluster_slug.clear_cache">
<code class="descname">clear_cache</code><span class="sig-paren">(</span><em>margindims=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/slugpy/cluster_slug/cluster_slug.html#cluster_slug.clear_cache"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#slugpy.cluster_slug.cluster_slug.clear_cache" title="Permalink to this definition">¶</a></dt>
<dd><p>This method deletes from the cache</p>
<dl class="docutils">
<dt>Parameters</dt>
<dd><dl class="first last docutils">
<dt>margindims <span class="classifier-delimiter">:</span> <span class="classifier">listlike of integers</span></dt>
<dd>list of marginalised dimensions that should be removed
from the cache, in the same format as make_cache; if
left as None, the cache is completely emptied</dd>
<dt>filters <span class="classifier-delimiter">:</span> <span class="classifier">listlike of strings</span></dt>
<dd>list of photometric filters to use; if left as None, and
only 1 set of photometric filters has been defined for
the cluster_slug object, that set will be used by
default</dd>
</dl>
</dd>
<dt>Returns</dt>
<dd>Nothing</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="slugpy.cluster_slug.cluster_slug.del_filters">
<code class="descname">del_filters</code><span class="sig-paren">(</span><em>filters</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/slugpy/cluster_slug/cluster_slug.html#cluster_slug.del_filters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#slugpy.cluster_slug.cluster_slug.del_filters" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove a set of filters, freeing the memory associated with
them. Note that this does not delete the underlying library
data, just the data for the KD tree used internally.</p>
<dl class="docutils">
<dt>Parameters</dt>
<dd><dl class="first last docutils">
<dt>filters <span class="classifier-delimiter">:</span> <span class="classifier">iterable of stringlike</span></dt>
<dd>list of filter names</dd>
</dl>
</dd>
<dt>Returns</dt>
<dd>Nothing</dd>
<dt>Raises</dt>
<dd>KeyError if the input set of filters is not loaded</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="slugpy.cluster_slug.cluster_slug.draw_phot">
<code class="descname">draw_phot</code><span class="sig-paren">(</span><em>physprop</em>, <em>physidx=None</em>, <em>photerr=None</em>, <em>nsample=1</em>, <em>filters=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/slugpy/cluster_slug/cluster_slug.html#cluster_slug.draw_phot"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#slugpy.cluster_slug.cluster_slug.draw_phot" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a randomly-drawn sample of clusters for a given filter
set</p>
<dl class="docutils">
<dt>Parameters:</dt>
<dd><dl class="first last docutils">
<dt>physprop <span class="classifier-delimiter">:</span> <span class="classifier">arraylike</span></dt>
<dd>physical properties to be used; the final dimension of
the input must have len(physidx) indices, or nphys
indicates if physidx is None; if the input is a
multidimensional array, the operation is vectorized over
the leading dimensions physical properties</dd>
<dt>physidx <span class="classifier-delimiter">:</span> <span class="classifier">arraylike</span></dt>
<dd>indices of the physical quantities being constrained; if
left as None, all physical properties are set, and
physprop must have a trailing dimension of size equal to
nphys; otherwise this must be an arraylike of &lt;= nphys
positive integers, each unique and in the range [0,
nphys), specying which physical dimensions are
constrained</dd>
<dt>photerr <span class="classifier-delimiter">:</span> <span class="classifier">arraylike, shape (nphot)</span></dt>
<dd>photometric errors to apply to the output photometry;
these are added in quadrature with the kernel density
estimation bandwidth</dd>
<dt>nsample <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>number of random samples to draw for each set of
physical properties; must be positive</dd>
<dt>filters <span class="classifier-delimiter">:</span> <span class="classifier">listlike of strings</span></dt>
<dd>list of photometric filters to use; if left as None, and
only 1 set of photometric filters has been defined for
the cluster_slug object, that set will be used by
default</dd>
</dl>
</dd>
<dt>Returns:</dt>
<dd><dl class="first last docutils">
<dt>samples <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (nsample, nphys+nphot)</span></dt>
<dd>random sample drawn from the kernel density object; for
the final dimension in the output, the first nphys
elements are the physical quantities, the next nphot are
the photometric quantities</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="slugpy.cluster_slug.cluster_slug.draw_sample">
<code class="descname">draw_sample</code><span class="sig-paren">(</span><em>photerr=None</em>, <em>nsample=1</em>, <em>filters=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/slugpy/cluster_slug/cluster_slug.html#cluster_slug.draw_sample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#slugpy.cluster_slug.cluster_slug.draw_sample" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a randomly-drawn sample of clusters for a given filter
set</p>
<dl class="docutils">
<dt>Parameters:</dt>
<dd><dl class="first last docutils">
<dt>photerr <span class="classifier-delimiter">:</span> <span class="classifier">arraylike, shape (nphot)</span></dt>
<dd>photometric errors to apply to the output photometry;
these are added in quadrature with the kernel density
estimation bandwidth</dd>
<dt>nsample <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>number of random samples to draw for each set of
physical properties; must be positive</dd>
<dt>filters <span class="classifier-delimiter">:</span> <span class="classifier">listlike of strings</span></dt>
<dd>list of photometric filters to use; if left as None, and
only 1 set of photometric filters has been defined for
the cluster_slug object, that set will be used by
default</dd>
</dl>
</dd>
<dt>Returns:</dt>
<dd><dl class="first last docutils">
<dt>samples <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (nsample, nphys+nphot)</span></dt>
<dd>random sample drawn from the kernel density object; for
the final dimension in the output, the first nphys
elements are the physical quantities, the next nphot are
the photometric quantities</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="slugpy.cluster_slug.cluster_slug.filter_units">
<code class="descname">filter_units</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/slugpy/cluster_slug/cluster_slug.html#cluster_slug.filter_units"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#slugpy.cluster_slug.cluster_slug.filter_units" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns list of all available filter units</p>
<dl class="docutils">
<dt>Parameters:</dt>
<dd>None</dd>
<dt>Returns:</dt>
<dd><dl class="first last docutils">
<dt>units <span class="classifier-delimiter">:</span> <span class="classifier">list of strings</span></dt>
<dd>list of available filter units</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="slugpy.cluster_slug.cluster_slug.filters">
<code class="descname">filters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/slugpy/cluster_slug/cluster_slug.html#cluster_slug.filters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#slugpy.cluster_slug.cluster_slug.filters" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns list of all available filters</p>
<dl class="docutils">
<dt>Parameters:</dt>
<dd>None</dd>
<dt>Returns:</dt>
<dd><dl class="first last docutils">
<dt>filters <span class="classifier-delimiter">:</span> <span class="classifier">list of strings</span></dt>
<dd>list of available filter names</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="slugpy.cluster_slug.cluster_slug.filtersets">
<code class="descname">filtersets</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/slugpy/cluster_slug/cluster_slug.html#cluster_slug.filtersets"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#slugpy.cluster_slug.cluster_slug.filtersets" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns list of all currently-loaded filter sets</p>
<dl class="docutils">
<dt>Parameters:</dt>
<dd>None</dd>
<dt>Returns:</dt>
<dd><dl class="first last docutils">
<dt>filtersets <span class="classifier-delimiter">:</span> <span class="classifier">list of list of strings</span></dt>
<dd>list of currently-loaded filter sets</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="slugpy.cluster_slug.cluster_slug.load_data">
<code class="descname">load_data</code><span class="sig-paren">(</span><em>filter_name</em>, <em>bandwidth=None</em>, <em>force_reload=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/slugpy/cluster_slug/cluster_slug.html#cluster_slug.load_data"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#slugpy.cluster_slug.cluster_slug.load_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Loads photometric data for the specified filter into memory</p>
<dl class="docutils">
<dt>Parameters:</dt>
<dd><dl class="first last docutils">
<dt>filter_name <span class="classifier-delimiter">:</span> <span class="classifier">string</span></dt>
<dd>name of filter to load</dd>
<dt>bandwidth <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>default bandwidth for this filter</dd>
<dt>force_reload <span class="classifier-delimiter">:</span> <span class="classifier">bool</span></dt>
<dd>if True, reinitialize the data even if has already been
stored</dd>
</dl>
</dd>
<dt>Returns:</dt>
<dd>None</dd>
<dt>Raises:</dt>
<dd>ValueError, if filter_name is not one of the available
filters</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="slugpy.cluster_slug.cluster_slug.logL">
<code class="descname">logL</code><span class="sig-paren">(</span><em>physprop</em>, <em>photprop</em>, <em>photerr=None</em>, <em>filters=None</em>, <em>margindim=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/slugpy/cluster_slug/cluster_slug.html#cluster_slug.logL"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#slugpy.cluster_slug.cluster_slug.logL" title="Permalink to this definition">¶</a></dt>
<dd><p>This function returns the natural log of the likelihood
function evaluated at a particular log mass, log age,
extinction, and set of log luminosities</p>
<dl class="docutils">
<dt>Parameters:</dt>
<dd><dl class="first last docutils">
<dt>physprop <span class="classifier-delimiter">:</span> <span class="classifier">arraylike, shape (nhpys) or (…, nphys)</span></dt>
<dd>array giving values of the log M, log T, and A_V; for a
multidimensional array, the operation is vectorized over
the leading dimensions; if created with use_extinct =
False, the A_V dimension should be omitted.
Will also include variable any variable parameters VPx if
they are requested.</dd>
<dt>photprop <span class="classifier-delimiter">:</span> <span class="classifier">arraylike, shape (nfilter) or (…, nfilter)</span></dt>
<dd>array giving the photometric values; for a
multidimensional array, the operation is vectorized over
the leading dimensions</dd>
<dt>photerr <span class="classifier-delimiter">:</span> <span class="classifier">arraylike, shape (nfilter) or (…, nfilter)</span></dt>
<dd>array giving photometric errors; for a multidimensional
array, the operation is vectorized over the leading
dimensions</dd>
<dt>filters <span class="classifier-delimiter">:</span> <span class="classifier">listlike of strings</span></dt>
<dd>list of photometric filters to use; if left as None, and
only 1 set of photometric filters has been defined for
the cluster_slug object, that set will be used by
default</dd>
<dt>margindim <span class="classifier-delimiter">:</span> <span class="classifier">int | arraylike of ints | None</span></dt>
<dd>The index or indices of the physical or photometric
properties to be maginalized over, numbered from 0 -
nphys-1 for physical properties and from nphys - nfilter +
nfilter - 1 for photometric properties. If this keyword is
set, then physprop and/or photprop should have fewer
than nphys or nphot elements due to the omission of
marginalised dimensions. If all physical or photometric
dimensions are marginalised out, that corresponding
argument for physprop or photprop should be set to None</dd>
</dl>
</dd>
<dt>Returns:</dt>
<dd><dl class="first last docutils">
<dt>logL <span class="classifier-delimiter">:</span> <span class="classifier">float or arraylike</span></dt>
<dd>natural log of the likelihood function</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="slugpy.cluster_slug.cluster_slug.make_approx_phot">
<code class="descname">make_approx_phot</code><span class="sig-paren">(</span><em>phys</em>, <em>squeeze=True</em>, <em>filter_ignore=None</em>, <em>filters=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/slugpy/cluster_slug/cluster_slug.html#cluster_slug.make_approx_phot"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#slugpy.cluster_slug.cluster_slug.make_approx_phot" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an object that can be used for a fast approximation of
the PDF of photometric properties that corresponds to a set of
physical properties. The PDF produced by summing over the
points returned is guaranteed to account for at least 1-reltol
of the marginal photometric probability, and to represent the
shape of the PDF in photometric space within a local accuracy
of reltol as well.</p>
<dl class="docutils">
<dt>Parameters:</dt>
<dd><dl class="first last docutils">
<dt>phys <span class="classifier-delimiter">:</span> <span class="classifier">arraylike, shape (nphys) or (N, nphys)</span></dt>
<dd>the set or sets of physical properties for which the
approximation is to be generated</dd>
<dt>squeeze <span class="classifier-delimiter">:</span> <span class="classifier">bool</span></dt>
<dd>if True, the representation returned will be squeezed to
minimize the number of points included, using reltol as
the error tolerance</dd>
<dt>filter_ignore <span class="classifier-delimiter">:</span> <span class="classifier">None or listlike of bool</span></dt>
<dd>if None, the kernel density representation returned
covers all filters; otherwise this must be a listlike of
bool, one entry per filter, with a value of False
indicating that filter should be excluded from the
values returned; suppressing filters can allow for more
efficient representations</dd>
<dt>filters <span class="classifier-delimiter">:</span> <span class="classifier">listlike of strings</span></dt>
<dd>list of photometric filters to use; if left as None, and
only 1 set of photometric filters has been defined for
the cluster_slug object, that set will be used by
default</dd>
</dl>
</dd>
<dt>Returns:</dt>
<dd><dl class="first last docutils">
<dt>x <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (M, nphot), or a list of such arrays</span></dt>
<dd>an array containing the list of points to be used for
the approximation</dd>
<dt>wgts <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (M), or a list of such arrays</span></dt>
<dd>an array containing the weights of the points</dd>
</dl>
</dd>
<dt>Notes:</dt>
<dd>if the requested relative tolerance cannot be reached for
numerical reasons (usually because the input point is too
far from the library to allow accurate computation), x and
wgts will be return as None, and a warning will be issued</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="slugpy.cluster_slug.cluster_slug.make_approx_phys">
<code class="descname">make_approx_phys</code><span class="sig-paren">(</span><em>phot</em>, <em>photerr=None</em>, <em>squeeze=True</em>, <em>phys_ignore=None</em>, <em>filters=None</em>, <em>tol=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/slugpy/cluster_slug/cluster_slug.html#cluster_slug.make_approx_phys"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#slugpy.cluster_slug.cluster_slug.make_approx_phys" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an object that can be used for a fast approximation of
the PDF of physical properties that corresponds to a set of
photometric properties. The PDF produced by summing over the
points returned is guaranteed to account for at least 1-reltol
of the marginal photometric probability, and to represent the
shape of the PDF in photometric space within a local accuracy
of reltol as well.</p>
<dl class="docutils">
<dt>Parameters:</dt>
<dd><dl class="first last docutils">
<dt>phot <span class="classifier-delimiter">:</span> <span class="classifier">arraylike, shape (nfilter) or (N, nfilter)</span></dt>
<dd>the set or sets of photometric properties for which the
approximation is to be generated</dd>
<dt>photerr <span class="classifier-delimiter">:</span> <span class="classifier">arraylike, shape (nfilter) or (N, nfilter)</span></dt>
<dd>array giving photometric errors; the number of elements
in the output lists will be the size that results from
broadcasting together the leading dimensions of phot and
photerr</dd>
<dt>squeeze <span class="classifier-delimiter">:</span> <span class="classifier">bool</span></dt>
<dd>if True, the representation returned will be squeezed to
minimize the number of points included, using reltol as
the error tolerance</dd>
<dt>phys_ignore <span class="classifier-delimiter">:</span> <span class="classifier">None or listlike of bool</span></dt>
<dd>if None, the kernel density representation returned
covers all physical properties; otherwise this must be a
listlike of bool, one entry per physical dimension, with
a value of False indicating that dimension should be
excluded from the values returned; suppressing
dimensions can allow for more efficient representations</dd>
<dt>filters <span class="classifier-delimiter">:</span> <span class="classifier">listlike of strings</span></dt>
<dd>list of photometric filters to use; if left as None, and
only 1 set of photometric filters has been defined for
the cluster_slug object, that set will be used by
default</dd>
<dt>tol <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd>if set, this tolerance overrides the value of reltol</dd>
</dl>
</dd>
<dt>Returns:</dt>
<dd><dl class="first last docutils">
<dt>x <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (M, nphys), or a list of such arrays</span></dt>
<dd>an array containing the list of points to be used for
the approximation, where nphys is the number of
physical dimensions being returned</dd>
<dt>wgts <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (M), or a list of such arrays</span></dt>
<dd>an array containing the weights of the points</dd>
</dl>
</dd>
<dt>Notes:</dt>
<dd>if the requested relative tolerance cannot be reached for
numerical reasons (usually because the input point is too
far from the library to allow accurate computation), x and
wgts will be return as None, and a warning will be issued</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="slugpy.cluster_slug.cluster_slug.make_cache">
<code class="descname">make_cache</code><span class="sig-paren">(</span><em>margindims</em>, <em>filters=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/slugpy/cluster_slug/cluster_slug.html#cluster_slug.make_cache"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#slugpy.cluster_slug.cluster_slug.make_cache" title="Permalink to this definition">¶</a></dt>
<dd><p>This method builds a cache to do faster calculation of PDFs
where certain dimensions are marginalised out. If such caches
exist, they are used automatically by all the computation
methods.</p>
<dl class="docutils">
<dt>Parameters</dt>
<dd><dl class="first last docutils">
<dt>margindims <span class="classifier-delimiter">:</span> <span class="classifier">listlike of integers</span></dt>
<dd>list of dimensions to be marginalised out; physical
dimensions go from 0 - nphys-1, photometric dimensions
from nphys to nphys + nphot - 1; note that the indexing
depends on the filter set specified by filters</dd>
<dt>filters <span class="classifier-delimiter">:</span> <span class="classifier">listlike of strings</span></dt>
<dd>list of photometric filters to use; if left as None, and
only 1 set of photometric filters has been defined for
the cluster_slug object, that set will be used by
default</dd>
</dl>
</dd>
<dt>Returns</dt>
<dd>Nothing</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="slugpy.cluster_slug.cluster_slug.mcmc">
<code class="descname">mcmc</code><span class="sig-paren">(</span><em>photprop</em>, <em>photerr=None</em>, <em>mc_walkers=100</em>, <em>mc_steps=500</em>, <em>mc_burn_in=50</em>, <em>filters=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/slugpy/cluster_slug/cluster_slug.html#cluster_slug.mcmc"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#slugpy.cluster_slug.cluster_slug.mcmc" title="Permalink to this definition">¶</a></dt>
<dd><p>This function returns a sample of MCMC walkers for cluster
mass, age, and extinction</p>
<dl class="docutils">
<dt>Parameters:</dt>
<dd><dl class="first last docutils">
<dt>photprop <span class="classifier-delimiter">:</span> <span class="classifier">arraylike, shape (nfilter) or (…, nfilter)</span></dt>
<dd>array giving the photometric values; for a
multidimensional array, the operation is vectorized over
the leading dimensions</dd>
<dt>photerr <span class="classifier-delimiter">:</span> <span class="classifier">arraylike, shape (nfilter) or (…, nfilter)</span></dt>
<dd>array giving photometric errors; for a multidimensional
array, the operation is vectorized over the leading
dimensions</dd>
<dt>mc_walkers <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>number of walkers to use in the MCMC</dd>
<dt>mc_steps <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>number of steps in the MCMC</dd>
<dt>mc_burn_in <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd>number of steps to consider “burn-in” and discard</dd>
<dt>filters <span class="classifier-delimiter">:</span> <span class="classifier">listlike of strings</span></dt>
<dd>list of photometric filters to use; if left as None, and
only 1 set of photometric filters has been defined for
the cluster_slug object, that set will be used by
default</dd>
</dl>
</dd>
<dt>Returns</dt>
<dd><dl class="first last docutils">
<dt>samples <span class="classifier-delimiter">:</span> <span class="classifier">array</span></dt>
<dd>array of sample points returned by the MCMC</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="slugpy.cluster_slug.cluster_slug.mpdf">
<code class="descname">mpdf</code><span class="sig-paren">(</span><em>idx</em>, <em>photprop</em>, <em>photerr=None</em>, <em>ngrid=128</em>, <em>qmin=None</em>, <em>qmax=None</em>, <em>grid=None</em>, <em>norm=True</em>, <em>filters=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/slugpy/cluster_slug/cluster_slug.html#cluster_slug.mpdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#slugpy.cluster_slug.cluster_slug.mpdf" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the marginal probability for one or mode physical
quantities for one or more input sets of photometric
properties. Output quantities are computed on a grid of
values, in the same style as meshgrid</p>
<dl class="docutils">
<dt>Parameters:</dt>
<dd><dl class="first last docutils">
<dt>idx <span class="classifier-delimiter">:</span> <span class="classifier">int or listlike containing ints</span></dt>
<dd>index of the physical quantity whose PDF is to be
computed; 0 = log M, 1 = log T, 2 = A_V, (2 or 3)+x = VPx; 
if this is an iterable, the joint distribution of the indicated
quantities is returned</dd>
<dt>photprop <span class="classifier-delimiter">:</span> <span class="classifier">arraylike, shape (nfilter) or (…, nfilter)</span></dt>
<dd>array giving the photometric values; for a
multidimensional array, the operation is vectorized over
the leading dimensions</dd>
<dt>photerr <span class="classifier-delimiter">:</span> <span class="classifier">arraylike, shape (nfilter) or (…, nfilter)</span></dt>
<dd>array giving photometric errors; for a multidimensional
array, the operation is vectorized over the leading
dimensions</dd>
<dt>ngrid <span class="classifier-delimiter">:</span> <span class="classifier">int or listlike containing ints</span></dt>
<dd>number of points in each dimension of the output grid;
if this is an iterable, it must have the same number of
elements as idx</dd>
<dt>qmin <span class="classifier-delimiter">:</span> <span class="classifier">float or listlike</span></dt>
<dd>minimum value in the output grid in each quantity; if
left as None, defaults to the minimum value in the
library; if this is an iterable, it must contain the
same number of elements as idx</dd>
<dt>qmax <span class="classifier-delimiter">:</span> <span class="classifier">float or listlike</span></dt>
<dd>maximum value in the output grid in each quantity; if
left as None, defaults to the maximum value in the
library; if this is an iterable, it must contain the
same number of elements as idx</dd>
<dt>grid <span class="classifier-delimiter">:</span> <span class="classifier">listlike of arrays</span></dt>
<dd>set of values defining the grid on which the PDF is to
be evaluated, in the same format used by meshgrid</dd>
<dt>norm <span class="classifier-delimiter">:</span> <span class="classifier">bool</span></dt>
<dd>if True, returned pdf’s will be normalized to integrate
to 1</dd>
<dt>filters <span class="classifier-delimiter">:</span> <span class="classifier">listlike of strings</span></dt>
<dd>list of photometric filters to use; if left as None, and
only 1 set of photometric filters has been defined for
the cluster_slug object, that set will be used by
default</dd>
</dl>
</dd>
<dt>Returns:</dt>
<dd><dl class="first last docutils">
<dt>grid_out <span class="classifier-delimiter">:</span> <span class="classifier">array</span></dt>
<dd>array of values at which the PDF is evaluated; contents
are the same as returned by meshgrid</dd>
<dt>pdf <span class="classifier-delimiter">:</span> <span class="classifier">array</span></dt>
<dd>array of marginal posterior probabilities at each point
of the output grid, for each input cluster; the leading
dimensions match the leading dimensions produced by
broadcasting the leading dimensions of photprop and
photerr together, while the trailing dimensions match
the dimensions of the output grid</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="slugpy.cluster_slug.cluster_slug.mpdf_approx">
<code class="descname">mpdf_approx</code><span class="sig-paren">(</span><em>x</em>, <em>wgts</em>, <em>dims='phys'</em>, <em>dims_return=None</em>, <em>ngrid=64</em>, <em>qmin='all'</em>, <em>qmax='all'</em>, <em>grid=None</em>, <em>norm=True</em>, <em>filters=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/slugpy/cluster_slug/cluster_slug.html#cluster_slug.mpdf_approx"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#slugpy.cluster_slug.cluster_slug.mpdf_approx" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the marginal posterior PDF computed from a kernel
density approximation returned by make_approx_phys or
make_approx_phot. Outputs are computed on a grid of values, in
the same style as meshgrid.</p>
<dl class="docutils">
<dt>Parameters:</dt>
<dd><dl class="first last docutils">
<dt>x <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (M, ndim), or a list of such arrays</span></dt>
<dd>array of points retured by make_approx_phot or
make_approx_phys</dd>
<dt>wgts <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (M) or a list of such arrays</span></dt>
<dd>array of weights returned by make_approx_phot or
make_approx_phys</dd>
<dt>dims <span class="classifier-delimiter">:</span> <span class="classifier">‘phys’ | ‘phot’ | arraylike of ints</span></dt>
<dd>dimensions covered by x and wgts; the strings ‘phys’ or
‘phot’ indicate that they cover all physical or
photometric dimensions, and correspond to the defaults
returned by make_approx_phys and make_approx_phot,
respectively; if dims is an array of ints, these specify
the dimensions covered by x and wgts, where the
physical dimensions are numbered 0, 1, … nphys-1, and
the photometric ones are nphys, nphys+1,
… nphys+nphot-1</dd>
<dt>dims_return <span class="classifier-delimiter">:</span> <span class="classifier">None or arraylike of ints</span></dt>
<dd>if None, the output PDF has the same dimensions as
specified in dims; if not, then dims_return must be a
subset of dims, and a marginal PDF in certain dimensions
will be generated</dd>
<dt>ngrid <span class="classifier-delimiter">:</span> <span class="classifier">int or listlike containing ints</span></dt>
<dd>number of points in each dimension of the output grid;
if this is an iterable, it must have the same number of
elements as idx</dd>
<dt>qmin <span class="classifier-delimiter">:</span> <span class="classifier">float | listlike | ‘zoom’ | ‘all’ </span></dt>
<dd>minimum value in the output grid in each quantity; if
this a float, it is applied to each dimension; if it is
an iterable, it must contain the same number of elements
as the number of dimensions being returned, as gives the
minimum in each dimension; if it is ‘zoom’ or ‘all’, the
minimum is chosen automatically, with ‘zoom’ focusing on
a region encompassing the probability maximum, and ‘all’
encompassing all the points in the representation</dd>
<dt>qmax <span class="classifier-delimiter">:</span> <span class="classifier">float | listlike | ‘zoom’ | ‘all’</span></dt>
<dd>same as qmin, but for the maximum of the output grid</dd>
<dt>grid <span class="classifier-delimiter">:</span> <span class="classifier">listlike of arrays</span></dt>
<dd>set of values defining the grid on which the PDF is to
be evaluated, in the same format used by meshgrid</dd>
<dt>norm <span class="classifier-delimiter">:</span> <span class="classifier">bool</span></dt>
<dd>if True, returned pdf’s will be normalized to integrate
to 1</dd>
<dt>filters <span class="classifier-delimiter">:</span> <span class="classifier">listlike of strings</span></dt>
<dd>list of photometric filters to use; if left as None, and
only 1 set of photometric filters has been defined for
the cluster_slug object, that set will be used by
default</dd>
</dl>
</dd>
<dt>Returns:</dt>
<dd><dl class="first last docutils">
<dt>grid_out <span class="classifier-delimiter">:</span> <span class="classifier">array</span></dt>
<dd>array of values at which the PDF is evaluated; contents
are the same as returned by meshgrid</dd>
<dt>pdf <span class="classifier-delimiter">:</span> <span class="classifier">array</span></dt>
<dd>array of marginal posterior probabilities at each point
of the output grid, for each input cluster; the leading
dimensions match the leading dimensions produced by
broadcasting the leading dimensions of photprop and
photerr together, while the trailing dimensions match
the dimensions of the output grid</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="slugpy.cluster_slug.cluster_slug.mpdf_gen">
<code class="descname">mpdf_gen</code><span class="sig-paren">(</span><em>fixeddim</em>, <em>fixedprop</em>, <em>margindim</em>, <em>ngrid=128</em>, <em>qmin=None</em>, <em>qmax=None</em>, <em>grid=None</em>, <em>norm=True</em>, <em>filters=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/slugpy/cluster_slug/cluster_slug.html#cluster_slug.mpdf_gen"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#slugpy.cluster_slug.cluster_slug.mpdf_gen" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the marginal probability for one or more physical or
photometric properties, keeping other properties fixed and
marginalizing over other quantities. This is the most general
marginal PDF routine provided.</p>
<dl class="docutils">
<dt>Parameters:</dt>
<dd><dl class="first last docutils">
<dt>fixeddim <span class="classifier-delimiter">:</span> <span class="classifier">int | arraylike of ints | None</span></dt>
<dd>The index or indices of the physical or photometric
properties to be held fixed; physical properties are
numbered 0 … nphys-1, and photometric ones are numbered
nphys … nphys + nphot - 1. This can also be set to
None, in which case no properties are held fixed.</dd>
<dt>fixedprop <span class="classifier-delimiter">:</span> <span class="classifier">array | None</span></dt>
<dd>The values of the properties being held fixed; the size
of the final dimension must be equal to the number of
elements in fixeddim, and if fixeddim is None, this must
be too</dd>
<dt>margindim <span class="classifier-delimiter">:</span> <span class="classifier">int | arraylike of ints | None</span></dt>
<dd>The index or indices of the physical or photometric
properties to be maginalized over, numbered in the same
way as with fixeddim; if set to None, no marginalization
is performed</dd>
<dt>ngrid <span class="classifier-delimiter">:</span> <span class="classifier">int or listlike containing ints</span></dt>
<dd>number of points in each dimension of the output grid;
if this is an iterable, it must have nphys + nphot -
len(fixeddim) - len(margindim) elements</dd>
<dt>qmin <span class="classifier-delimiter">:</span> <span class="classifier">float | arraylike</span></dt>
<dd>minimum value in the output grid in each quantity; if
left as None, defaults to the minimum value in the
library; if this is an iterable, it must contain a
number of elements equal to nphys + nphot -
len(fixeddim) - len(margindim)</dd>
<dt>qmax <span class="classifier-delimiter">:</span> <span class="classifier">float | arraylike</span></dt>
<dd>maximum value in the output grid in each quantity; if
left as None, defaults to the maximum value in the
library; if this is an iterable, it must have the same
number of elements as qmin</dd>
<dt>grid <span class="classifier-delimiter">:</span> <span class="classifier">listlike of arrays</span></dt>
<dd>set of values defining the grid on which the PDF is to
be evaluated, in the same format used by meshgrid</dd>
<dt>norm <span class="classifier-delimiter">:</span> <span class="classifier">bool</span></dt>
<dd>if True, returned pdf’s will be normalized to integrate
to 1</dd>
<dt>filters <span class="classifier-delimiter">:</span> <span class="classifier">listlike of strings</span></dt>
<dd>list of photometric filters to use; if left as None, and
only 1 set of photometric filters has been defined for
the cluster_slug object, that set will be used by
default</dd>
</dl>
</dd>
<dt>Returns:</dt>
<dd><dl class="first last docutils">
<dt>grid_out <span class="classifier-delimiter">:</span> <span class="classifier">array</span></dt>
<dd>array of values at which the PDF is evaluated; contents
are the same as returned by meshgrid</dd>
<dt>pdf <span class="classifier-delimiter">:</span> <span class="classifier">array</span></dt>
<dd>array of marginal posterior probabilities at each point
of the output grid, for each input set of properties; the leading
dimensions match the leading dimensions produced by
broadcasting the leading dimensions of photprop and
photerr together, while the trailing dimensions match
the dimensions of the output grid</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="slugpy.cluster_slug.cluster_slug.mpdf_phot">
<code class="descname">mpdf_phot</code><span class="sig-paren">(</span><em>idx</em>, <em>physprop</em>, <em>ngrid=128</em>, <em>qmin=None</em>, <em>qmax=None</em>, <em>grid=None</em>, <em>norm=True</em>, <em>filters=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/slugpy/cluster_slug/cluster_slug.html#cluster_slug.mpdf_phot"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#slugpy.cluster_slug.cluster_slug.mpdf_phot" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the marginal probability for one or more photometric
quantities corresponding to an input set or distribution of
physical properties. Output quantities are computed on a grid of
values, in the same style as meshgrid.</p>
<dl class="docutils">
<dt>Parameters:</dt>
<dd><dl class="first last docutils">
<dt>idx <span class="classifier-delimiter">:</span> <span class="classifier">int or listlike containing ints</span></dt>
<dd>index of the photometric quantity whose PDF is to be
computed, starting at 0; indices correspond to the order
of elements in the filters argument; if this is an
iterable, the joint distribution of the indicated
quantities is returned</dd>
<dt>physprop <span class="classifier-delimiter">:</span> <span class="classifier">arraylike, shape (nphys) or (…, nphys)</span></dt>
<dd>physical properties to be used; if this is an array of
nphys elements, these give the physical properties; if
it is a multidimensional array, the operation is
vectoried over the leading dimensions
physical properties – the function must take an array
of (nphys) elements as an input, and return a floating
point value representing the PDF evaluated at that set
of physical properties as an output</dd>
<dt>ngrid <span class="classifier-delimiter">:</span> <span class="classifier">int or listlike containing ints</span></dt>
<dd>number of points in each dimension of the output grid;
if this is an iterable, it must have the same number of
elements as idx</dd>
<dt>qmin <span class="classifier-delimiter">:</span> <span class="classifier">float or listlike</span></dt>
<dd>minimum value in the output grid in each quantity; if
left as None, defaults to the minimum value in the
library; if this is an iterable, it must contain the
same number of elements as idx</dd>
<dt>qmax <span class="classifier-delimiter">:</span> <span class="classifier">float or listlike</span></dt>
<dd>maximum value in the output grid in each quantity; if
left as None, defaults to the maximum value in the
library; if this is an iterable, it must contain the
same number of elements as idx</dd>
<dt>grid <span class="classifier-delimiter">:</span> <span class="classifier">listlike of arrays</span></dt>
<dd>set of values defining the grid on which the PDF is to
be evaluated, in the same format used by meshgrid</dd>
<dt>norm <span class="classifier-delimiter">:</span> <span class="classifier">bool</span></dt>
<dd>if True, returned pdf’s will be normalized to integrate
to 1</dd>
<dt>filters <span class="classifier-delimiter">:</span> <span class="classifier">listlike of strings</span></dt>
<dd>list of photometric filters to use; if left as None, and
only 1 set of photometric filters has been defined for
the cluster_slug object, that set will be used by
default</dd>
</dl>
</dd>
<dt>Returns:</dt>
<dd><dl class="first last docutils">
<dt>grid_out <span class="classifier-delimiter">:</span> <span class="classifier">array</span></dt>
<dd>array of values at which the PDF is evaluated; contents
are the same as returned by meshgrid</dd>
<dt>pdf <span class="classifier-delimiter">:</span> <span class="classifier">array</span></dt>
<dd>array of marginal posterior probabilities at each point
of the output grid, for each input set of properties; the leading
dimensions match the leading dimensions produced by
broadcasting the leading dimensions of photprop and
photerr together, while the trailing dimensions match
the dimensions of the output grid</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="slugpy.cluster_slug.cluster_slug.squeeze_rep">
<code class="descname">squeeze_rep</code><span class="sig-paren">(</span><em>x</em>, <em>wgts</em>, <em>dims=None</em>, <em>filters=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/slugpy/cluster_slug/cluster_slug.html#cluster_slug.squeeze_rep"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#slugpy.cluster_slug.cluster_slug.squeeze_rep" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes an input array of positions and weights that form a
kernel density representation and approximates them using
fewer points, using an error tolerance of reltol</p>
<dl class="docutils">
<dt>Parameters:</dt>
<dd><dl class="first last docutils">
<dt>x <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (N, ndim)</span></dt>
<dd>an array of points forming a kernel density
representation; on exit, x will be resized to (M, ndim)
with M &lt;= N</dd>
<dt>wgts <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (N)</span></dt>
<dd>an array of weights for the kernel density
representation; on exit, wgts will be resized to (M),
with M &lt;= N</dd>
<dt>dims <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (ndim)</span></dt>
<dd>array specifying which dimensions in the kernel density
representation the coordinates in x correspond to; if
left as None, they are assumed to correspond to the
first ndim dimensions in the data set</dd>
<dt>filters <span class="classifier-delimiter">:</span> <span class="classifier">listlike of strings</span></dt>
<dd>list of photometric filters to use; if left as None, and
only 1 set of photometric filters has been defined for
the cluster_slug object, that set will be used by
default</dd>
</dl>
</dd>
<dt>Returns:</dt>
<dd>Nothing</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">cluster_slug: Bayesian Inference of Star Cluster Properties</a><ul>
<li><a class="reference internal" href="#getting-the-default-library">Getting the Default Library</a></li>
<li><a class="reference internal" href="#basic-usage">Basic Usage</a></li>
<li><a class="reference internal" href="#using-cluster-slug-in-parallel">Using cluster_slug in Parallel</a></li>
<li><a class="reference internal" href="#making-your-own-library">Making Your Own Library</a></li>
<li><a class="reference internal" href="#variable-mode-imf">Variable Mode IMF</a></li>
<li><a class="reference internal" href="#full-documentation-of-slugpy-cluster-slug">Full Documentation of slugpy.cluster_slug</a></li>
</ul>
</li>
</ul>
<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="bayesphot.html" title="previous chapter">bayesphot: Bayesian Inference for Stochastic Stellar Populations</a></li>
      <li>Next: <a href="sfr_slug.html" title="next chapter">sfr_slug: Bayesian Inference of Star Formation Rates</a></li>
  </ul></li>
</ul>
</div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/cluster_slug.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2014, Mark Krumholz, Michele Fumagalli, et al..
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.6.3</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.6</a>
      
      |
      <a href="_sources/cluster_slug.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>